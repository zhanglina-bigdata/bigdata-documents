[TOC]

# hive数据类型



## 基本数据类型



| Hive数据类型 | Java数据类型 | 长度                                                 | 例子                                 |
| ------------ | ------------ | ---------------------------------------------------- | ------------------------------------ |
| TINYINT      | byte         | 1byte有符号整数                                      | 20                                   |
| SMALINT      | short        | 2byte有符号整数                                      | 20                                   |
| INT          | int          | 4byte有符号整数                                      | 20                                   |
| BIGINT       | long         | 8byte有符号整数                                      | 20                                   |
| BOOLEAN      | boolean      | 布尔类型，true或者false                              | TRUE  FALSE                          |
| FLOAT        | float        | 单精度浮点数                                         | 3.14159                              |
| DOUBLE       | double       | 双精度浮点数                                         | 3.14159                              |
| STRING       | string       | 字符系列。可以指定字符集。可以使用单引号或者双引号。 | ‘now is the time’ “for all good men” |
| TIMESTAMP    |              | 时间类型                                             |                                      |
| BINARY       |              | 字节数组                                             |                                      |

## 集合数据类型

| 数据类型 | 描述                                                         | 语法示例                                        |
| -------- | ------------------------------------------------------------ | ----------------------------------------------- |
| STRUCT   | 和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。 | struct() 例如struct<street:string, city:string> |
| MAP      | MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键->值对是’first’->’John’和’last’->’Doe’，那么可以通过字段名[‘last’]获取最后一个元素 | map() 例如map<string, int>                      |
| ARRAY    | 数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。 | Array() 例如array<string>                       |

# hive常用操作

## DDL操作

| 语义                                                         | 中文描述                             | 用例                                              |
| ------------------------------------------------------------ | ------------------------------------ | ------------------------------------------------- |
| CREATE DATABASE [IF NOT EXISTS] database_name<br/>[COMMENT database_comment]<br/>[LOCATION hdfs_path] <br />[WITH DBPROPERTIES <br />(property_name=property_value, ...)]; | 创建数据库                           | create database db_hive2 location '/db_hive2.db'; |
| show databases;                                              | 查询数据库                           | show databases like 'db_hive*';                   |
| desc database db_hive;                                       | 查看数据库详情                       | desc database 【extended】 db_hive;               |
| use db_hive;                                                 | 切换当前数据库                       |                                                   |
| alter database db_hive set dbproperties('createtime'='20170830'); | 修改数据库                           |                                                   |
| drop database db_hive2 ***\*cascade\****;                    | 删除数据库                           | 数据不为空，强制删除                              |
|                                                              | 创建表（内部表\外部表）              |                                                   |
|                                                              | 修改表（修改表名、修改列、修改分区） |                                                   |
|                                                              | 删除表                               |                                                   |


## DML操作

### 数据导入

1. load

   load data [local] inpath '数据的path' [overwrite] into table student [partition (partcol1=val1,…)];

2. insert 

3. 创建表时通过Location指定加载数据路径

   ```sql
   create external table if not exists student5(
          id int, name string
         )
         row format delimited fields terminated by '\t'
        location '/student;
   ```

4. import数据到指定hive表中

   ```sql
   import table student2 from '/user/hive/warehouse/export/student';
   ```

### 数据导出

1. 将查询结果导出

   ```sql
   1）将查询的结果导出到本地
   hive (default)> insert overwrite local directory '/opt/module/hive/datas/export/student' select * from student;
   2）将查询的结果格式化导出到本地
   hive(default)>insert overwrite local directory '/opt/module/hive/datas/export/student1'
    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'    select * from student;
   3）将查询的结果导出到HDFS上(没有local)
   hive (default)> insert overwrite directory '/user/atguigu/student2'
                ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' select * from student;
   ```

2. Hadoop命令导出到本地

   ```shell
   dfs -get /user/hive/warehouse/student/student.txt /opt/module/datas/export/student3.txt;
   ```

3. Hive Shell 命令导出

   ```shell
   hive -e 'select * from default.student;' >
    /opt/module/hive/datas/export/student4.txt;
   ```

4. Export导出到HDFS上

   ```sql
   export table default.student to '/user/hive/warehouse/export/student';
   ```

### 数据查询

1. 基本查询

   select * from

2. 分组

   group/having

3. join语句

   内连接、左连接、右连接、全连接

4. 排序

   order by(全局排序)

   sort by（每个reduce排序）

   distribute by(分区排序)

   Cluster By

### 分区表和分桶表

1. 分区表

   ```sql
     --1. 创建分区表
     create table dept_partition2(
     deptno int, dname string, loc string)
     partitioned by (day string, hour string)
     row format delimited fields terminated by '\t';
   ```

   ```sql
     --2. 加载数据
     load data local inpath '/opt/module/hive/datas/dept_20200401.log' into table
     dept_partition2 partition(day='20200401', hour='12');
   ```

   ```sql
    --3. 把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式
       dfs -mkdir -p
     /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=13;
     dfs -put /opt/module/datas/dept_20200401.log             /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=13;
      -- 1）方式一：上传数据后修复
      --执行修复命令
       msck repair table dept_partition2;
       --2)方式二：上传数据后添加分区
       alter table dept_partition2 add partition(day='201709',hour='14');
       --3）方式三：创建文件夹后load数据到分区
       load data local inpath '/opt/module/hive/datas/dept_20200401.log' into table
       dept_partition2 partition(day='20200401',hour='15');
   ```

   ```sql
       --4.动态分区调整
       （1）开启动态分区功能（默认true，开启）
        hive.exec.dynamic.partition=true
       （2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）
        hive.exec.dynamic.partition.mode=nonstrict
       （3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000
   	 hive.exec.max.dynamic.partitions=1000
   	（4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。
   	 hive.exec.max.dynamic.partitions.pernode=100
   	（5）整个MR Job中，最大可以创建多少个HDFS文件。默认100000
   	 hive.exec.max.created.files=100000
   	（6）当有空分区生成时，是否抛出异常。一般不需要设置。默认false
   	 hive.error.on.empty.partition=false
   
   ```

2. 分桶表

   ```sql
   --创建分桶表
   create table stu_buck(id int, name string)
   clustered by(id) 
   into 4 buckets
   row format delimited fields terminated by '\t';
   ```

   ```tex
   分桶规则：
   根据结果可知：Hive的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中
   ```

3. 抽样查询

   语法: TABLESAMPLE(BUCKET x OUT OF y) 

   ```sql
   select * from stu_buck tablesample(bucket 1 out of 4 on id)
   ```

   